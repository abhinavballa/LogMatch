# LogMatch
# Flow Log Parsing Program

## Assumptions
1. Custom log formats are specified in a separate file with indices for destination port and protocol.

## Edge Cases
1. Missing or malformed files.
2. Empty rows or rows with insufficient data.
3. Large file sizes and performance optimization.

## How to Run
1. Place the flow log file and lookup table file in the same directory as the program.
2. Run the program with the following command:
python3 match.py <lookup_table.csv> <flow_logs.txt>
3. The output will be saved to `output.txt`.

## AI Assistance
This project utilized AI assistance for the following tasks:

- **Creating Input Files**: I used a Large Language Model (LLM) to generate sample input files, including flow logs and lookup tables, to test various scenarios. The LLM was prompted to create realistic examples of flow logs and lookup tables based on the problem description. I verified the accuracy of these files by manually reviewing them to ensure they matched the expected format and content.

- **Identifying Edge Cases**: The LLM helped identify potential edge cases that the program should handle, such as missing files, malformed data, and custom log formats. I provided the LLM with the problem description and asked it to list possible edge cases. I then reviewed these cases to ensure they were comprehensive and relevant.

- **Function Development**: I used the LLM to create functions that:
  - **Convert Lookup Table to Dictionary**: The LLM generated a function to convert the lookup table’s CSV into a dictionary with keys as a tuple of the destination port and protocol, and values as the tag that it maps to. This function is used to easily map each record from the flow log by matching its port and protocol. If a match is not found, it adds to the ‘Untagged’ key in the `tag_counts` dictionary. I verified the accuracy of this function by testing it with sample lookup tables and ensuring it correctly mapped ports and protocols to tags.
  - **Write Output to File**: The LLM assisted in creating a function to write the output to a file. I checked this function by running it with sample data and verifying that the output file was correctly formatted and contained the expected data.
  - **Protocol Number Mapping**: The LLM helped create a dictionary to match protocol numbers in each log record to their respective names. I verified this dictionary by comparing it against known protocol numbers and names.

To ensure the accuracy of the generated code, I followed these steps:
1. **Manual Review**: I manually reviewed each portion of code generated by the LLM to ensure it met the requirements and was correctly implemented.
2. **Testing**: I tested each function with sample data to verify it produced the expected output.
3. **Comparison with Known Solutions**: Where possible, I compared the generated code with known solutions or existing implementations to ensure consistency and correctness.

The code solves the assigned problem by efficiently parsing flow log data and mapping it to tags based on a lookup table. It handles various edge cases, such as missing or malformed files, and provides a clear output of tag counts and port/protocol combination counts. The use of dictionaries for lookup and output formatting ensures efficient processing of large datasets.
